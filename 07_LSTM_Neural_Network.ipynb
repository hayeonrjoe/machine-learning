{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Google Colab에서 Kaggle API를 사용하기 위한 라이브러리 설치\n",
        "!pip install kaggle\n",
        "\n",
        "# Kaggle API 토큰 업로드\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "MwRJ16jyjMnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Kaggle API 토큰을 사용자 디렉토리로 복사하고 권한 설정\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "o7McJ-bhOFIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Kaggle에서 데이터셋 다운로드\n",
        "!kaggle datasets download -d hetulmehta/website-classification"
      ],
      "metadata": {
        "id": "2hHU3jGpOIqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 다운로드한 데이터셋 압축 해제\n",
        "!unzip website-classification.zip"
      ],
      "metadata": {
        "id": "SbH9Q-mUOKaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 라이브러리 및 모듈 로드\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "OEWFwhkhMuEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation"
      ],
      "metadata": {
        "id": "gw-QOiXzNOVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 로드 및 전처리\n",
        "wc_data = pd.read_csv('website_classification.csv')\n",
        "# 'Streaming Services' 카테고리를 1로, 다른 카테고리를 0으로 변환\n",
        "wc_data['Outlook'] = (wc_data['Category'] == 'Streaming Services').astype(int)\n",
        "# 훈련 및 테스트 데이터 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(wc_data['cleaned_website_text'], wc_data['Outlook'], test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "9Gyj6yJTNV57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "IAmdFu5gRlFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "metadata": {
        "id": "NcXiXqiSTPML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip glove*.zip"
      ],
      "metadata": {
        "id": "bUzCObn1ULXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n",
        "!pwd"
      ],
      "metadata": {
        "id": "ArJQawF1UXK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "file_path = 'glove.6B.50d.txt'\n",
        "\n",
        "if os.path.exists(file_path):\n",
        "    print(f\"The file '{file_path}' exists.\")\n",
        "else:\n",
        "    print(f\"The file '{file_path}' does not exist. Please check the path.\")"
      ],
      "metadata": {
        "id": "XxpkOF4LU90t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "print(\"Current Working Directory:\", os.getcwd())"
      ],
      "metadata": {
        "id": "cGgcvy7BVDsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "# GloVe 워드 임베딩 모델 로드\n",
        "glove_model = KeyedVectors.load_word2vec_format('glove.6B.50d.txt', binary=False, no_header=True)"
      ],
      "metadata": {
        "id": "Tc8xKAK7R5y9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 텍스트 데이터 토큰화\n",
        "tokenizer = Tokenizer(num_words=10000)\n",
        "tokenizer.fit_on_texts(wc_data['cleaned_website_text'])\n",
        "X_train_tokens = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_tokens = tokenizer.texts_to_sequences(X_test)"
      ],
      "metadata": {
        "id": "BQKI9ZqmSADR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 시퀀스를 고정 길이로 패딩\n",
        "max_len = 100\n",
        "X_train_padded = pad_sequences(X_train_tokens, maxlen=max_len)\n",
        "X_test_padded = pad_sequences(X_test_tokens, maxlen=max_len)"
      ],
      "metadata": {
        "id": "jCK26quXSCna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 토큰을 워드 임베딩 벡터로 변환\n",
        "X_train_vectors = np.zeros((len(X_train_padded), max_len, 50))\n",
        "X_test_vectors = np.zeros((len(X_test_padded), max_len, 50))\n",
        "\n",
        "# 정수 인덱스를 단어로 변환하기 위한 역 매핑\n",
        "reverse_word_index = {index: word for word, index in tokenizer.word_index.items()}\n",
        "\n",
        "# 훈련 데이터에 대한 워드 임베딩 벡터 생성\n",
        "for i, seq in enumerate(X_train_padded):\n",
        "    for j, index in enumerate(seq):\n",
        "        word = reverse_word_index.get(index, '')  # 인덱스에 해당하는 단어 가져오기\n",
        "        if word in glove_model:\n",
        "            X_train_vectors[i][j] = glove_model[word]\n",
        "\n",
        "# 테스트 데이터에 대한 워드 임베딩 벡터 생성\n",
        "for i, seq in enumerate(X_test_padded):\n",
        "    for j, index in enumerate(seq):\n",
        "        word = reverse_word_index.get(index, '')  # 인덱스에 해당하는 단어 가져오기\n",
        "        if word in glove_model:\n",
        "            X_test_vectors[i][j] = glove_model[word]"
      ],
      "metadata": {
        "id": "C668AwOCSEl-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 워드 임베딩 매트릭스 생성\n",
        "embedding_dim = 50\n",
        "embedding_matrix = np.zeros((len(tokenizer.word_index) + 1, embedding_dim))\n",
        "\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if word in glove_model:\n",
        "        embedding_matrix[i] = glove_model[word]"
      ],
      "metadata": {
        "id": "Mo0xXWJOaLP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-gpu"
      ],
      "metadata": {
        "id": "EXpN7z1Za3B0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# GPU 사용 가능 여부 확인\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "if len(physical_devices) > 0:\n",
        "    print(\"TensorFlow-GPU is available and configured.\")\n",
        "else:\n",
        "    print(\"No GPU detected. TensorFlow will use CPU.\")"
      ],
      "metadata": {
        "id": "g_SG6nJCbJfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TensorFlow 업그레이드\n",
        "!pip install --upgrade tensorflow"
      ],
      "metadata": {
        "id": "GKJv-kRhbjNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, Flatten\n",
        "\n",
        "# LSTM 기반 신경망 모델 생성\n",
        "model = Sequential()\n",
        "\n",
        "# LSTM 레이어 추가\n",
        "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2, input_shape=(max_len, embedding_dim)))\n",
        "\n",
        "# 이진 분류를 위한 Dense 레이어 추가\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# 모델 구조 출력\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "MfMgDJifNdlt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 훈련\n",
        "model.fit(X_train_vectors, y_train, epochs=10, batch_size=32, validation_split=0.2)"
      ],
      "metadata": {
        "id": "ATbSf8ZLNhCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 및 평가\n",
        "loss, accuracy = model.evaluate(X_test_vectors, y_test)\n",
        "print(f'Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "id": "KlXNqAyjNrcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 훈련 기록 시각화\n",
        "history = model.fit(X_train_vectors, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# 훈련 정확도 및 검증 정확도 그래프\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# 훈련 손실 및 검증 손실 그래프\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JKS34aebem8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# 혼동 행렬 시각화\n",
        "predictions = model.predict(X_test_vectors)\n",
        "y_pred = (predictions > 0.5).astype(int)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2fqrSebsfU3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# ROC 곡선 및 AUC 시각화\n",
        "predictions = model.predict(X_test_vectors)\n",
        "fpr, tpr, thresholds = roc_curve(y_test, predictions)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FVQV1jFqfafD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}